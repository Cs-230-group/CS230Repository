# SafeMS

## Goals

One of our goals is to become a viable solution for detecting bots across a wide range of social platforms and messaging channels. We also want to promote online safety, critical thinking in regards to the internet, as well as offer tools to verify the authenticity of digital media. In the process of our aforementioned goals, we want to uphold fairness, privacy, and respect for users. 

## Idea Origination

The reason we chose this topic was because of the considerable decline of internet safety knowledge and simultaneous rise of bot activity online. With monumental developments in generative AI models, they have quickly fallen under the use of bad actors: ranging from innocent photos to falsified speeches given by influential figures, we want to help create a space between human and ingenuine, programmed activity. 

## Purpose/Values/Mission

Our purpose is to create an online world that is safer and more trustworthy. We want to develop advanced tools and systems that identify and suppress falsified activity and misinformation. By providing accessible resources and solutions, we are able to foster a digital environment where truth prevails and users are able to make more informed decisions when consuming information online.

## Key Questions 

Three key questions drive our company: How can we reduce the amount of false positively detected bots after human evaluation? How can we comply with online privacy rules? How can we stay ahead of evolving technology and strategies used by bad actors?

## Strategy with Ethical Impacts and Ethical Safeguards

### OKRs

We set our sights on three outcomes, one of which is reduced bot activity on social media. We should accomplish this by successfully suppressing 5000 bot accounts, utilizing an in-house created bot detecting algorithm. We also want to partner with two major social media or messaging companies to make this happen. 

Our second outcome is to educate the general public on bots and suspicious activity online. We want this course to be easy and practical, helping people recognize signs of automated accounts and understand malicious tactics like scamming and phishing. Offering this course for free ensures that everyone has the knowledge to stay safe online. At the same time, we also want to run a social media campaign in the same vein as our free course in order to spread awareness of it and reach a bigger audience.

Lastly, we want to analyze bot trends by building a database of unique bot accounts categorized around their activities. Using this, we can identify patterns and remain ahead of bad actors.
 
### Metrics

We measure progress on our first outcome by taking into consideration the numbers of successful bot removals and bot detection accuracy.

Our second outcomeâ€™s progress should be evaluated by the engagement on our online content and courses, such as views, likes, comments, and course completion rates.

Progress on our third outcome is assessed by considering the number of bots reported by users weekly and monthly, and additionally by how well we can predict bot trends.

### Ethical Impacts/Issues

We recognize that we may infringe on online freedom of speech and catch false positives with our algorithm. Using an algorithm to analyze every post on a platform can raise concern about when it is suppressing bots and when it infringes on the rights of users. Furthermore, partnerships with social platforms usually lead to sharing data and resources, raising concerns about data privacy.

In spreading awareness and educating the general public about bots and malicious activity online, we may produce misinformation or biased content. Data privacy is also a concern here when using course metrics as a means to determine our success.

Collecting bot data can lead to unintentionally storing human user data labeled as bots. Accumulating such a database may be used for malicious purposes. 

### Ethical Safeguards

We want to remedy the issues of our first goal by open-sourcing our algorithm, and making sure the output of our algorithm is heavily moderated by a team of real people. We will also make transparent the types of data that we will collect, with consent from users.

Prior to publishing any sort of content to our socials or online course, we will check with experts to ensure that the information that we provide is accurate. We will also seek user consent for any data obtaining activities. 

Once again, user consent would be sought out. Bot reports should use minimal data until experts are able to sift and determine if the report is legitimate. Access to our database will only be limited to trusted and verified individuals. 

